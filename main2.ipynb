{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "z7vYMic92jf2",
    "outputId": "6ec85d51-962f-4a1b-f086-09db1a63fe1e"
   },
   "outputs": [],
   "source": [
    "# # comment when run locally\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd /gdrive/My\\ Drive/similar_faces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rVdqfGug2lCi",
    "outputId": "4734a6db-6acb-45ee-ddf0-e8bd46e030dd"
   },
   "outputs": [],
   "source": [
    "# # uncomment when run locally\n",
    "# !rm -rf /data_celeba\n",
    "# !mkdir /data_celeba\n",
    "# %cp celeba_identity.txt /data_celeba\n",
    "# %cp img_align_celeba.zip /data_celeba\n",
    "# %cd /data_celeba\n",
    "# !unzip -q img_align_celeba.zip\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t50Sdd02BrX"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from collections import defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G9YHmdxpRybo",
    "outputId": "057dd27f-9b9e-4487-ca29-27da2a1012b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda unavailable\n"
     ]
    }
   ],
   "source": [
    "sns.set()\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Cuda device: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('Cuda unavailable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6oJAzSb2Brd"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarFaceDatasetOnline(Dataset):\n",
    "    def __init__(self, n_classes, n_samples, train_test_split=0.95, is_train=True):\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.transform = transforms.ToTensor()\n",
    "        \n",
    "        with open('celeba_identity.txt') as f:\n",
    "            filename_identity = [x.split() for x in f.readlines()]\n",
    "\n",
    "        identity_filenames_dict = defaultdict(list)\n",
    "        for i in filename_identity:\n",
    "            identity_filenames_dict[int(i[1])].append(i[0])\n",
    "\n",
    "        identity_filenames_list = list(filter(lambda x: len(x) > n_samples, (map(lambda x: x[1], sorted(identity_filenames_dict.items(), key=lambda x: x[0])))))\n",
    "        train_test_split_index = int(0.95 * len(identity_filenames_list))\n",
    "        if is_train:\n",
    "            self.identity_filenames_list = identity_filenames_list[:train_test_split_index]\n",
    "        else:\n",
    "            self.identity_filenames_list = identity_filenames_list[train_test_split_index:]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.identity_filenames_list) // self.n_classes\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return torch.stack([self.transform(Image.open(f'img_align_celeba/{x}')) for xs in self.identity_filenames_list[index:index+self.n_classes] for x in random.sample(xs, n_samples)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGCXWV9f2Brf"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ib3aoGPK2Brg"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "            \n",
    "        x += residual\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, out_channels=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], 2)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, out_channels)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_net = ResNet(ResidualBlock, [2, 2, 2, 2], out_channels=10)\n",
    "        \n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)\n",
    "        \n",
    "    def forward(self, a, p, n):\n",
    "        a_out = self.embedding_net(a)\n",
    "        p_out = self.embedding_net(p)\n",
    "        n_out = self.embedding_net(n)\n",
    "        return (a_out, p_out, n_out)\n",
    "    \n",
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_net = ResNet(ResidualBlock, [2, 2, 2, 2], out_channels=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anchor_positive_pairs(n_classes, n_samples):\n",
    "    for positive_class in range(n_classes):\n",
    "        for anchor in range(n_samples):\n",
    "            for positive in range(n_samples):\n",
    "                if anchor != positive:\n",
    "                    yield positive_class * n_samples + anchor, positive_class * n_samples + positive\n",
    "\n",
    "def get_triplets(embeddings, mode='random_hard_negative'):\n",
    "    triplets = []\n",
    "    pdist = pairwise_distances(embeddings)\n",
    "    for a, p in anchor_positive_pairs(n_classes, n_samples):\n",
    "        positive_class = a // n_samples\n",
    "        dap = pdist[a, p]\n",
    "        dan = pdist[a, :].copy()\n",
    "        dan[positive_class*n_samples:(positive_class+1)*n_samples] = np.inf\n",
    "\n",
    "        loss = dap - dan\n",
    "\n",
    "        # hardest negative\n",
    "        hardest_negative_index = np.argmax(loss)\n",
    "        \n",
    "        if mode == 'hardest_negative':\n",
    "            triplets.append([a, p, hardest_negative_index])\n",
    "            continue\n",
    "\n",
    "        # random hard negative\n",
    "        hard_negatives = np.where(loss > 0)[0]\n",
    "        random_hard_negative_index = np.random.choice(hard_negatives) if len(hard_negatives) > 0 \\\n",
    "                                                                    else hardest_negative_index\n",
    "\n",
    "        triplets.append([a, p, random_hard_negative_index])\n",
    "    return np.array(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJctWy0d2Brh"
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "n_classes = 10\n",
    "n_samples = 4\n",
    "margin = 1.0\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_dataset = SimilarFaceDatasetOnline(n_classes=n_classes, n_samples=n_samples, is_train=True)\n",
    "test_dataset = SimilarFaceDatasetOnline(n_classes=n_classes, n_samples=n_samples, is_train=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = EmbeddingNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.TripletMarginLoss(margin=margin)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKWdq7hC2Brl"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load checkpoint\n",
    "# checkpoint = torch.load('checkpoint_online', map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1678202152252197\n",
      "1.3771870136260986\n",
      "1.5175034999847412\n",
      "1.2008720636367798\n",
      "1.4778987169265747\n",
      "1.5287015438079834\n",
      "1.3120559453964233\n",
      "1.21099054813385\n",
      "1.3140149116516113\n",
      "1.3785618543624878\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2773cc634d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        embeddings = model(batch.squeeze(0).to(device))\n",
    "\n",
    "        triplets = get_triplets(embeddings.detach().numpy(), mode='random_hard_negative')\n",
    "\n",
    "        loss = criterion(\n",
    "            embeddings[triplets[:, 0]], \n",
    "            embeddings[triplets[:, 1]],\n",
    "            embeddings[triplets[:, 2]]\n",
    "        )\n",
    "        print(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5CUKOdilGtn"
   },
   "source": [
    "## Test on custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xzk5zP01gWBJ",
    "outputId": "a1a60a32-21a2-4ec1-cb37-4c64fe0437b9"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count = 22\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((217, 178)),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x: x[:3]\n",
    "])\n",
    "\n",
    "images = torch.empty(220, 3, 217, 178)\n",
    "j = 0\n",
    "for i in range(count):\n",
    "    pathname = os.path.join('./data', f'c{i+1}')\n",
    "    for filename in glob.glob(f'{pathname}/*'):\n",
    "        images[j] = transform(Image.open(filename))\n",
    "        j += 1\n",
    "    print(f'{i} ', end='')\n",
    "\n",
    "embeddings = model.get_embedding(images).detach().numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings)\n",
    "df = pd.DataFrame()\n",
    "df['pca-1'] = pca_result[:, 0]\n",
    "df['pca-2'] = pca_result[:, 1]\n",
    "df['label'] = [i for i in range(count) for j in range(10)]\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x='pca-1', \n",
    "    y='pca-2',\n",
    "    hue='label',\n",
    "    palette=sns.color_palette(\"hls\", count),\n",
    "    data=df\n",
    ")\n",
    "print(f'\\nExplained variance vatio: {pca.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_face_index = 200\n",
    "k = 10\n",
    "l2_distances = ((embeddings[target_face_index] - embeddings) ** 2).sum(axis=1)\n",
    "closest_k_face_indices = np.argsort(l2_distances)[:k]\n",
    "closest_k_faces = images[closest_k_face_indices]\n",
    "print(l2_distances[closest_k_face_indices])\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(np.transpose(images[target_face_index], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(np.transpose(make_grid(closest_k_faces, 5), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on celeba data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "count = 22\n",
    "with open('celeba_identity.txt') as f:\n",
    "    filename_identity = [x.split() for x in f.readlines()]\n",
    "    identity_filenames_dict = defaultdict(list)\n",
    "    for i in filename_identity:\n",
    "        identity_filenames_dict[int(i[1])].append(i[0])\n",
    "    identity_filenames_list = []\n",
    "    for i in range(len(identity_filenames_dict)):\n",
    "        tmp = []\n",
    "        for filename in identity_filenames_dict[i+1]:\n",
    "            tmp.append(filename)\n",
    "        if len(tmp) >= 10:\n",
    "            identity_filenames_list.append(tmp[:10])\n",
    "    mask = random.sample(range(len(identity_filenames_list)), count)\n",
    "    identity_filenames_list_ = []\n",
    "    for i in mask:\n",
    "        identity_filenames_list_.append(identity_filenames_list[i])    \n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "images = []\n",
    "for i in range(count):\n",
    "    tmp = []\n",
    "    for j in range(10):\n",
    "        filename = identity_filenames_list[i][j]\n",
    "        images.append(transform(Image.open(f'./img_align_celeba/{filename}')))\n",
    "images = torch.stack(images)\n",
    "\n",
    "embeddings = model.get_embedding(images)\n",
    "embeddings = embeddings.detach().numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(embeddings)\n",
    "df = pd.DataFrame()\n",
    "df['pca-1'] = pca_result[:, 0]\n",
    "df['pca-2'] = pca_result[:, 1]\n",
    "df['label'] = [i for i in range(count) for j in range(10)]\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x='pca-1', \n",
    "    y='pca-2',\n",
    "    hue='label',\n",
    "    palette=sns.color_palette(\"hls\", count),\n",
    "    data=df\n",
    ")\n",
    "print(f'\\nExplained variance vatio: {pca.explained_variance_ratio_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_face_index = 144\n",
    "k = 3\n",
    "l2_distances = ((embeddings[target_face_index] - embeddings) ** 2).sum(axis=1)\n",
    "closest_k_face_indices = np.argsort(l2_distances)[:k]\n",
    "closest_k_faces = images[closest_k_face_indices]\n",
    "print(l2_distances[closest_k_face_indices])\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.imshow(np.transpose(images[target_face_index], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(np.transpose(make_grid(closest_k_faces, 5), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
